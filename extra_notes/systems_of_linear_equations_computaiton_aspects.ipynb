{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lack computation aspects in Lang's book\n",
    "\n",
    "Lang's book does not cover Gaussian Elimination, and the computation aspects builds around it. One consequence of that, is the readers of the book may rapidly develop the ability to tell how many solutions does a system of the linear equations have, but not being able to actually solve it as easily.\n",
    "\n",
    "This note aims to fill that gap of the book. It mainly follows the chapter 3 of [Friedberg's book](https://www.pearson.com/us/higher-education/program/Friedberg-Linear-Algebra-4th-Edition/PGM252241.html). It is also inspired by [Pinkham's commentary](http://www.math.columbia.edu/~pinkham/LangCommentary.pdf) on Lang's book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on inverse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma 3.0.1.\n",
    "\n",
    "Let $A, B$ be $n \\times n$ matrices. If $A B = I$, then $B A = I$\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Since $A B = I$, then we have\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "A B - I &= \\mathit{0} \\\\\n",
    "B (A B - I) &= B \\mathit{0}\\\\\n",
    "(B A - I) B &= \\mathit{0} && \\text{(1)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Let $\\{e_1, ..., e_n\\}$ be a standard basis of $K^n$. Then we know $e_1, ..., e_n$ are linearly independent.\n",
    "\n",
    "We contend $\\{B e_1, ..., B e_n\\}$ is a basis too.\n",
    "\n",
    "Let $a_1, ..., a_n$ be scalars such that\n",
    "\n",
    "$$\n",
    "\\sum_{j = 1}^n a_j B e_j = \\mathit{0}\n",
    "$$\n",
    "\n",
    "then multiplying above by $A$ on the left, we have\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "A \\sum_{a_j = 1}^n a_j B e_j &= \\mathit{0} \\\\\n",
    "\\sum_{a_j = 1}^n A B a_j e_j &= \\mathit{0} \\\\\n",
    "\\sum_{a_j = 1}^n I a_j e_j &= \\mathit{0} \\\\\n",
    "\\sum_{a_j = 1}^n a_j e_j &= \\mathit{0}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "And since $e_1, ..., e_n$ are linearly independent, then we have $a_j = 0$ for $j = 1, ..., n$. Thus $\\{B e_1, ..., B e_n\\}$ is also a basis of $R^n$.\n",
    "\n",
    "Then multiplying (1) on the right by $e_j$, we have\n",
    "\n",
    "$$\n",
    "(B A - I) (B e_j) = \\mathit{0}\n",
    "$$\n",
    "\n",
    "for $j = 1, ..., n$.\n",
    "\n",
    "Let $v$ be any vector in $R^n$. Then there exists unique scalars $b_1, ..., b_n$ such that $v = \\sum_{j = 1}^n b_j (B e_j)$. Then we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(B A - I) v &= (B A - I) \\sum_{j = 1}^n b_j (B e_j) \\\\\n",
    "&= \\sum_{j = 1}^n b_j (B A - I) (B e_j) \\\\\n",
    "&= \\sum_{j = 1}^n b_j \\mathit{0} \\\\\n",
    "&= \\mathit{0}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\n",
    "B A - I = \\mathit{0}\n",
    "$$\n",
    "\n",
    "Hence $B A = I$. Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell in developed on exercises 9 and 10 in section 2.4 of Friedberg's book. \n",
    "\n",
    "### Lemma 3.0.2.\n",
    "Let $A$ and $B$ be $n \\times n$ matrices such that $AB$ is invertible. Prove that $A$ and $B$ are invertible. Give an example to show that arbitrary matrices $A$ and $B$ need not be invertible if $AB$ is invertible.\n",
    "\n",
    "#### Proof: \n",
    "\n",
    "Since $A B$ is invertible, then there exists a [unique](../2_matrices/2_3_multiplication_of_matrices.ipynb#Uniqueness-of-invertible-matrix) $n \\times n$ matrix $(A B)^{-1}$ as its inverse matrix.\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "(1) && (A B) (A B)^{-1} &= I \\\\\n",
    "(2) && (A B)^{-1} (A B) &= I\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Then by [theorem 3.2, matrix multiplication is distributive](../2_matrices/2_3_multiplication_of_matrices.ipynb#Theorem-3.2.), then from (1), we have\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "A (B (A B)^{-1}) &= (A B) (A B)^{-1} &= I \\\\\n",
    "(A B^{-1} A) B &= (A B)^{-1} (A B) &= I\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Then from [lemma 3.0.1](#Lemma-3.0.1.), we have\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "(B (A B)^{-1}) A &= I \\\\\n",
    "B (A B^{-1} A) &= I\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Hence $A$ is invertible, and its inverse is $B (A B)^{-1}$, and $B$ is invertible, and its inverse is $A B^{-1} A$. Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary matrix operations and elementary matrices\n",
    "\n",
    "### Definitions: Elementary row and column operation:\n",
    "\n",
    "Let $A$ be an $m \\times n$ matrices. Any one of the following three operations on the rows \\[columns\\] of $A$ is called an elementary row \\[column\\] operation:\n",
    "- (1) Interchanging any two rows \\[columns\\] of $A$.\n",
    "- (2) Multiplying any row \\[column\\] of $A$ by a nonzero scalar\n",
    "- (3) Adding any scalar multiple of a row \\[column\\] of $A$ to another row \\[column\\].\n",
    "\n",
    "Any of these three operations is called an **elementary operation**. Elementary operations are of **type 1, type 2, or type 3** depending on whether they are obtained by (1), (2), or (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition: Elementary matrix\n",
    "\n",
    "An $n \\times n$ elementary matrix is a matrix obtained by performing an elementary operation on $I_n$. The elementary matrix is said to be of type 1, 2, or 3 according to whether the elementary operation performed on $I_n$ is a type 1, 2, or 3 operation, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorem 3.1.\n",
    "\n",
    "Let $A$ be an $m \\times n$ matrix over field $K$, and suppose that $B$ is obtained from $A$ by performing an elementary row \\[column\\] operation.\n",
    "\n",
    "Then there exists an $m \\times n$ \\[$n \\times n$\\] elementary matrix $E$ such that $B = E A$ \\[$B = A E$\\].\n",
    "\n",
    "In fact, $E$ is obtained from $I_m$ \\[$I_n$\\] by performing the same elementary row the same elementary row \\[column\\] operation as that which was performed on $A$ to obtain $B$.\n",
    "\n",
    "Conversely, if $E$ is an elementary $m \\times m$ \\[$n x n$\\] matrix, then $EA$ \\[$AE$\\] is the matrix obtained from $A$ by performing the same elementary row \\[column\\] operation as that which produces $E$ from $I_m$ \\[$I_n$\\].\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let $A = (a_{i j})$.\n",
    "\n",
    "Then we know the $E A$ is an $m \\times n$ matrix, and the $i, j$-th component of $E A$ is $E_i \\cdot A^j$.\n",
    "\n",
    "Let's verify this theorem for elementary row operations only, and after that the case for elementary column operations can be easily verified by transposing the matrices involved in the former proof.\n",
    "\n",
    "#### Case 1: $B$ is obtained from a type 1 elementary row operation \n",
    "\n",
    "Let $B$ be the matrix obtained from $A$ by exchanging the $p$-th and the $q$-th row of $A$, and $E$ be the matrix obtained from $I_m$ by exchanging $p$-th and the $q$-th row of $I_m$.\n",
    "\n",
    "Then for any $i \\in \\{1, ... m\\} \\setminus \\{p, q\\} $, for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_i \\cdot A_j = (I_m)_i \\cdot A_j = a_{i j}\n",
    "$$\n",
    "\n",
    "And for $i = p$ and $i = q$, we have for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_p \\cdot A_j = (I_m)_q \\cdot A_j = a_{q j}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "E_q \\cdot A_j = (I_m)_p \\cdot A_j = a_{p j}\n",
    "$$\n",
    "\n",
    "Hence $E A$ is the same matrix as $A$, except the $p$-th row is interchanged with the $q$-th row. Thus $E A = B$.\n",
    "\n",
    "#### Case 2: $B$ is obtained from a type 2 elementary row operation \n",
    "\n",
    "Let $\\alpha$ be a scalar.\n",
    "\n",
    "Let $B$ be the matrix obtained from $A$ by multiplying its $p$-th row by $\\alpha$, and $E$ be the matrix obtained from $I_m$ by multiplying its $p$-th row by $\\alpha$.\n",
    "\n",
    "Then for $i = 1, ..., p - 1, p + 1, ..., m$, for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_i \\cdot A_j = (I_m)_i \\cdot A_j = a_{i j}\n",
    "$$\n",
    "\n",
    "And for $i = p$, for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_p \\cdot A_j = \\alpha (I_m)_p \\cdot A_j = \\alpha a_{p j}\n",
    "$$\n",
    "\n",
    "Hence $E A$ is the same matrix as $A$, except the $p$-th row is the $p$-th row of $A$ multiplied by $\\alpha$. Thus $E A = B$.\n",
    "\n",
    "#### Case 3: $B$ is obtained from a type 3 elementary row operation \n",
    "\n",
    "Let $\\alpha$ be a scalar.\n",
    "\n",
    "Let $B$ be the matrix obtained from $A$ by adding its $p$-th row by $\\alpha$ multiple of the $q$-th row, and $E$ be the matrix obtained from $I_m$ by adding its $p$-th row by $\\alpha$ multiple of the $q$-th row.\n",
    "\n",
    "Then for $i = 1, ..., p - 1, p + 1, ..., m$, for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_i \\cdot A_j = (I_m)_i \\cdot A_j = a_{i j}\n",
    "$$\n",
    "\n",
    "\n",
    "And for $i = p$, for $j = 1, ..., n$, we have\n",
    "\n",
    "$$\n",
    "E_p \\cdot A_j = (I_m)_p + \\alpha (I_m)_q \\cdot A_j = a_{i p} + \\alpha a_{i q}\n",
    "$$\n",
    "\n",
    "Hence $E A$ is the same matrix as $A$, except the $p$-th row is the $p$-th of $A$ added by the $p$-th row of $A$ multiplied by $\\alpha$. Thus $E A = B$.\n",
    "\n",
    "We can prove the same for the elementary column operations by transposing the matrices involved the the proof above.\n",
    "\n",
    "Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorem 3.2.\n",
    "\n",
    "Elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type.\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let $E$ be an elementary $n \\times n$ matrix. Then by definition, $E$ can be obtained by an elementary row operation on $I_n$. By reversing the step used to transform $I_n$ into $E$, we can transform $E$ back into $I_n$. The result is that $I_n$ can be obtained from $E$ by an elementary row operation of the same type.\n",
    "\n",
    "Then by [theorem 3.1](#Theorem-3.1.), there exists an $n \\times n$ elementary matrix $\\overline{E}$ such that $\\overline{E} E = I_n$. Then by [lemma 3.0.1](#Lemma-3.0.1.), we have $E \\overline{E} = I_n$. Thus $E$ is invertible, and $E^{-1} = \\overline{E}$. Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemma 3.3.0.\n",
    "\n",
    "Let $V$ and $W$ be two vector spaces with dimensions $n$ and $m$. Let $\\beta$ and $\\gamma$ be bases of $V$ and $W$.\n",
    "\n",
    "Let $L: V \\to W$ be a linear mapping. \n",
    "\n",
    "Recall that $\\phi_\\beta: V \\to K^n$ and $\\phi_\\gamma: W \\to K^m$ are [coordinate mappings](../isomorphism_of_vector_spaces.ipynb#Coordinates-with-respect-to-a-basis-determine-an-isomorphism).\n",
    "\n",
    "Let $L_\\phi = \\phi_\\gamma \\circ L \\circ \\phi_\\beta^{-1}$. Then\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Ker} L = \\dim \\operatorname{Ker} L_\\phi\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Im} L = \\dim \\operatorname{Im} L_\\phi\n",
    "$$\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let $v$ be any vector in $\\operatorname{Ker} L$. Then we have\n",
    "\n",
    "$$\n",
    "L(v) = \\mathit{0}\n",
    "$$\n",
    "\n",
    "And then we have\n",
    "\n",
    "$$\n",
    "L_\\phi(\\phi_\\beta(v)) = (\\phi_\\gamma \\circ L \\circ \\phi_\\beta^{-1} \\circ \\phi_\\beta) = (\\phi_\\gamma \\circ L)(v) = \\phi_\\gamma(L(v)) = \\phi_\\gamma(\\mathit{0}) = \\mathit{0}\n",
    "$$\n",
    "\n",
    "Hence $\\phi_\\beta(v) \\in \\operatorname{Ker} L_\\phi$.\n",
    "\n",
    "Let $v_\\phi$ be any vector in $\\operatorname{Ker} L_\\phi$. Then we have\n",
    "\n",
    "$$\n",
    "L_\\phi(v_\\phi) = \\mathit{0}\n",
    "$$\n",
    "\n",
    "And since\n",
    "\n",
    "$$\n",
    "L(\\phi_\\beta^{-1}(v_\\phi)) = (L \\circ \\phi_\\beta^{-1})(v_\\phi) = (\\phi_\\gamma^{-1} \\circ \\phi_\\gamma \\circ L \\circ \\phi_\\beta^{-1})(v_\\phi) = (\\phi_\\gamma^{-1} \\circ L_\\phi)(v_\\phi) = \\phi_\\gamma^{-1}(L_\\phi(v_\\phi)) = \\phi_\\gamma^{-1}(\\mathit{0}) = \\mathit{0}\n",
    "$$\n",
    "\n",
    "Hence $\\phi_\\beta^{-1}(v_\\phi) \\in \\operatorname{Ker} L$.\n",
    "\n",
    "Hence we can can see $\\phi_\\beta$ as a linear map from $\\operatorname{Ker} V$ to $\\operatorname{Ker} K^n$ ($\\phi_\\beta: \\operatorname{Ker} V \\to \\operatorname{Ker} K^n$), and $\\phi_\\beta^{-1}$ as a linear map from $K^n$ to $V$ ($\\phi_\\beta^{-1}: \\operatorname{Ker} K^n \\to \\operatorname{Ker} V$). And since $\\phi_\\beta$ is bijective, $\\phi_\\beta$ is an isomorphism. Hence $\\operatorname{Ker} V$ and $\\operatorname{Ker} K^n$ are isomorphic.\n",
    "\n",
    "Then by [corollary 7 in the isomorphism extra notes](./isomorphism_of_vector_spaces.ipynb#Corollary-7.), we have\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Ker} L = \\dim \\operatorname{Ker} L_\\phi\n",
    "$$\n",
    "\n",
    "And then by [theorem 3.2 in chapter 3.3](../3_linear_mappings/3_3_kernel_and_image_of_a_linear_map.ipynb#Theorem-3.2:-Kernel,-image,-and-dimensions), we have\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Im} L = \\dim V - \\dim \\operatorname{Ker} L = \\dim K^n - \\dim \\operatorname{Ker} L_\\phi = \\dim \\operatorname{Im} L_\\phi\n",
    "$$\n",
    "\n",
    "Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorem 3.3.\n",
    "\n",
    "Let $L: V \\to W$ be a linear map. Let $\\beta$ and $\\gamma$ be order bases of $V$ and $W$. Then\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Im} L = \\operatorname{rank} M_\\beta^\\gamma(L)\n",
    "$$\n",
    "\n",
    "### Proof\n",
    "\n",
    "Let $L_\\phi: K^n \\to K^m$ be a linear map such that $L_\\phi = \\phi_\\gamma \\circ L \\circ \\phi_\\beta^{-1}$. Let $E_1, ..., E_n$ be unit vectors in $K^n$. Then we have\n",
    "\n",
    "$$\n",
    "M_\\beta^\\gamma(L) = \\begin{pmatrix} L_\\phi(E_1), ..., L_\\phi(E_n) \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Then $M_\\beta^\\gamma(L)$ is associated to $L_\\phi$. By the [remark of theorem 3.2 in chapter 5.3](../5_scalar_products_and_orthogonality/5_3_rank.ipynb#Remark:-The-rank-of-a-matrix-is-the-dimension-of-the-image-of-the-associated-linear-map), we know\n",
    "\n",
    "$$\n",
    "\\operatorname{rank} M_\\beta^\\gamma(L) = \\dim \\operatorname{Im} L_\\phi\n",
    "$$\n",
    "\n",
    "Then by [lemma 3.3.0](#Lemma-3.3.0.), we have\n",
    "\n",
    "$$\n",
    "\\dim \\operatorname{Im} L_\\phi = \\dim \\operatorname{Im} L\n",
    "$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\n",
    "\\operatorname{rank} M_\\beta^\\gamma(L) = \\dim \\operatorname{Im} L\n",
    "$$\n",
    "\n",
    "Q.E.D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
